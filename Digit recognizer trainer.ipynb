{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4641 images belonging to 9 classes.\n",
      "Found 516 images belonging to 9 classes.\n",
      "Batch shape=(32, 28, 28, 1), min=0.000, max=255.000\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create generator\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_it = datagen.flow_from_directory('Model/training_data/', class_mode='categorical',target_size=(28, 28),color_mode='grayscale',batch_size=32,shuffle=True,seed=0)\n",
    "test_it =  datagen.flow_from_directory('Model/testing_data/', class_mode='categorical',target_size=(28, 28),color_mode='grayscale', batch_size=32,shuffle=True,seed=0)\n",
    "# confirm the iterator works\n",
    "batchX, batchy = train_it.next()\n",
    "\n",
    "batchX_test, batchy_test = test_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "#input_shape = (28, 28, 1)\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "#??flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batchX[12])\n",
    "print(batchy[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Creating a Sequential Model and adding the layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(9, activation='softmax'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, \n",
    "           padding='same',\n",
    "           activation='relu',\n",
    "           kernel_regularizer=regularizers.l2(0.0001),\n",
    "           input_shape=(28, 28 , 1)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(\n",
    "        100,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.0001)\n",
    "    ),\n",
    "    Dropout(0.2),\n",
    "    Dense(9, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "146/146 [==============================] - 14s 89ms/step - loss: 14.1787 - accuracy: 0.6918\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 12s 81ms/step - loss: 0.6873 - accuracy: 0.8854\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 13s 86ms/step - loss: 0.2926 - accuracy: 0.9345\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 13s 88ms/step - loss: 0.1914 - accuracy: 0.9559\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 11s 73ms/step - loss: 0.1733 - accuracy: 0.9657\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 12s 85ms/step - loss: 0.1301 - accuracy: 0.9711\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 14s 93ms/step - loss: 0.1215 - accuracy: 0.9745\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 13s 90ms/step - loss: 0.1000 - accuracy: 0.9747\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 14s 95ms/step - loss: 0.0952 - accuracy: 0.9816\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 15s 102ms/step - loss: 0.3098 - accuracy: 0.9632\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 14s 97ms/step - loss: 0.0907 - accuracy: 0.9801\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 17s 118ms/step - loss: 0.0681 - accuracy: 0.9826\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 19s 130ms/step - loss: 0.0888 - accuracy: 0.9859\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 18s 120ms/step - loss: 0.0822 - accuracy: 0.9830\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 17s 115ms/step - loss: 0.0696 - accuracy: 0.9905\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 18s 121ms/step - loss: 0.0638 - accuracy: 0.9927\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 20s 137ms/step - loss: 0.0713 - accuracy: 0.9875\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 17s 117ms/step - loss: 0.0480 - accuracy: 0.9891\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 13s 90ms/step - loss: 0.0621 - accuracy: 0.9924\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 14s 92ms/step - loss: 0.0659 - accuracy: 0.9924\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 12s 83ms/step - loss: 0.0527 - accuracy: 0.9937\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 15s 105ms/step - loss: 0.0586 - accuracy: 0.9938\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 14s 97ms/step - loss: 0.0471 - accuracy: 0.9925\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 14s 93ms/step - loss: 0.0359 - accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 15s 101ms/step - loss: 0.0382 - accuracy: 0.9953\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 14s 96ms/step - loss: 0.0382 - accuracy: 0.9966\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 14s 93ms/step - loss: 0.0503 - accuracy: 0.9926\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 14s 94ms/step - loss: 0.0380 - accuracy: 0.9970\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 16s 107ms/step - loss: 0.0458 - accuracy: 0.9942\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 16s 112ms/step - loss: 0.0334 - accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 15s 99ms/step - loss: 0.0412 - accuracy: 0.9946\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 14s 98ms/step - loss: 0.0458 - accuracy: 0.9945\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 15s 100ms/step - loss: 0.0382 - accuracy: 0.9953\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 16s 106ms/step - loss: 0.0530 - accuracy: 0.9941\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 13s 91ms/step - loss: 0.0304 - accuracy: 0.9974\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 13s 86ms/step - loss: 0.0325 - accuracy: 0.9963\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 13s 92ms/step - loss: 0.0497 - accuracy: 0.9944\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 12s 85ms/step - loss: 0.0520 - accuracy: 0.9937\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 14s 93ms/step - loss: 0.0569 - accuracy: 0.9943\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 12s 82ms/step - loss: 0.0433 - accuracy: 0.9953\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 12s 82ms/step - loss: 0.0425 - accuracy: 0.9951\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 12s 84ms/step - loss: 0.0278 - accuracy: 0.9995\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 16s 110ms/step - loss: 0.0396 - accuracy: 0.9974\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 13s 91ms/step - loss: 0.0501 - accuracy: 0.9965\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 12s 81ms/step - loss: 0.0347 - accuracy: 0.9968\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 14s 93ms/step - loss: 0.0306 - accuracy: 0.9992\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 14s 98ms/step - loss: 0.0385 - accuracy: 0.9974\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 13s 90ms/step - loss: 0.0362 - accuracy: 0.9986\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 14s 94ms/step - loss: 0.0291 - accuracy: 0.9993\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 13s 85ms/step - loss: 0.0316 - accuracy: 0.9983\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 13s 87ms/step - loss: 0.0307 - accuracy: 0.9983\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 15s 103ms/step - loss: 0.0354 - accuracy: 0.9976\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 13s 89ms/step - loss: 0.0391 - accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "146/146 [==============================] - 12s 81ms/step - loss: 0.0307 - accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "146/146 [==============================] - 13s 86ms/step - loss: 0.0335 - accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "146/146 [==============================] - 12s 84ms/step - loss: 0.0311 - accuracy: 0.9987\n",
      "Epoch 57/100\n",
      "146/146 [==============================] - 12s 84ms/step - loss: 0.0430 - accuracy: 0.9966\n",
      "Epoch 58/100\n",
      "146/146 [==============================] - 14s 95ms/step - loss: 0.0315 - accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "146/146 [==============================] - 12s 83ms/step - loss: 0.0451 - accuracy: 0.9958\n",
      "Epoch 60/100\n",
      "146/146 [==============================] - 14s 95ms/step - loss: 0.0325 - accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "146/146 [==============================] - 16s 111ms/step - loss: 0.0379 - accuracy: 0.9970\n",
      "Epoch 62/100\n",
      "146/146 [==============================] - 13s 91ms/step - loss: 0.0493 - accuracy: 0.9953\n",
      "Epoch 63/100\n",
      "146/146 [==============================] - 14s 97ms/step - loss: 0.0537 - accuracy: 0.9959\n",
      "Epoch 64/100\n",
      "146/146 [==============================] - 14s 97ms/step - loss: 0.0345 - accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "146/146 [==============================] - 14s 93ms/step - loss: 0.0442 - accuracy: 0.9945\n",
      "Epoch 66/100\n",
      "146/146 [==============================] - 15s 104ms/step - loss: 0.0461 - accuracy: 0.9963\n",
      "Epoch 67/100\n",
      "146/146 [==============================] - 17s 118ms/step - loss: 0.0338 - accuracy: 0.9982\n",
      "Epoch 68/100\n",
      "146/146 [==============================] - 16s 109ms/step - loss: 0.0366 - accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "146/146 [==============================] - 19s 129ms/step - loss: 0.0418 - accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "146/146 [==============================] - 16s 107ms/step - loss: 0.0629 - accuracy: 0.9946\n",
      "Epoch 71/100\n",
      "146/146 [==============================] - 16s 111ms/step - loss: 0.0405 - accuracy: 0.9977\n",
      "Epoch 72/100\n",
      "146/146 [==============================] - 17s 115ms/step - loss: 0.0392 - accuracy: 0.9982\n",
      "Epoch 73/100\n",
      "146/146 [==============================] - 15s 104ms/step - loss: 0.0331 - accuracy: 0.9984\n",
      "Epoch 74/100\n",
      "146/146 [==============================] - 16s 109ms/step - loss: 0.0366 - accuracy: 0.9979\n",
      "Epoch 75/100\n",
      "146/146 [==============================] - 17s 119ms/step - loss: 0.0411 - accuracy: 0.9973\n",
      "Epoch 76/100\n",
      "146/146 [==============================] - 19s 128ms/step - loss: 0.0323 - accuracy: 0.9990\n",
      "Epoch 77/100\n",
      "146/146 [==============================] - 16s 112ms/step - loss: 0.0382 - accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "146/146 [==============================] - 17s 118ms/step - loss: 0.0434 - accuracy: 0.9965\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 17s 118ms/step - loss: 0.0384 - accuracy: 0.9975\n",
      "Epoch 80/100\n",
      "146/146 [==============================] - 16s 109ms/step - loss: 0.0297 - accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "146/146 [==============================] - 18s 121ms/step - loss: 0.0371 - accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "146/146 [==============================] - 18s 126ms/step - loss: 0.0290 - accuracy: 0.9986\n",
      "Epoch 83/100\n",
      "146/146 [==============================] - 18s 122ms/step - loss: 0.0271 - accuracy: 0.9998\n",
      "Epoch 84/100\n",
      "146/146 [==============================] - 16s 111ms/step - loss: 0.0310 - accuracy: 0.9986\n",
      "Epoch 85/100\n",
      "146/146 [==============================] - 16s 113ms/step - loss: 0.0287 - accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "146/146 [==============================] - 18s 122ms/step - loss: 0.0294 - accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "146/146 [==============================] - 17s 112ms/step - loss: 0.0323 - accuracy: 0.9968\n",
      "Epoch 88/100\n",
      "146/146 [==============================] - 16s 108ms/step - loss: 0.0303 - accuracy: 0.9979\n",
      "Epoch 89/100\n",
      "146/146 [==============================] - 12s 85ms/step - loss: 0.0278 - accuracy: 0.9987\n",
      "Epoch 90/100\n",
      "146/146 [==============================] - 15s 101ms/step - loss: 0.0522 - accuracy: 0.9942\n",
      "Epoch 91/100\n",
      "146/146 [==============================] - 15s 102ms/step - loss: 0.0342 - accuracy: 0.9962\n",
      "Epoch 92/100\n",
      "146/146 [==============================] - 12s 84ms/step - loss: 0.0335 - accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "146/146 [==============================] - 14s 92ms/step - loss: 0.0331 - accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "146/146 [==============================] - 13s 86ms/step - loss: 0.0283 - accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "146/146 [==============================] - 12s 81ms/step - loss: 0.0442 - accuracy: 0.9978\n",
      "Epoch 96/100\n",
      "146/146 [==============================] - 13s 88ms/step - loss: 0.0360 - accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "146/146 [==============================] - 13s 86ms/step - loss: 0.0332 - accuracy: 0.9986\n",
      "Epoch 98/100\n",
      "146/146 [==============================] - 13s 86ms/step - loss: 0.0333 - accuracy: 0.9978\n",
      "Epoch 99/100\n",
      "146/146 [==============================] - 15s 100ms/step - loss: 0.0485 - accuracy: 0.9948\n",
      "Epoch 100/100\n",
      "146/146 [==============================] - 16s 109ms/step - loss: 0.0344 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f172d195b10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_it,epochs=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0692 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0692107230424881, 0.9941860437393188]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.2679465e-16, 6.5867959e-15, 9.4940621e-17, 2.2842148e-13,\n",
       "        3.1920186e-20, 1.2022881e-16, 7.5231229e-25, 1.0000000e+00,\n",
       "        1.3777193e-10]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batchX_test[1])\n",
    "print(batchX_test[1].shape)\n",
    "y = batchX_test[1].reshape(1,28,28,1)\n",
    "print(y.shape)\n",
    "#batchX_test[1]=batchX_test[1].reshape(1,28,28,1)\n",
    "model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"Model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
